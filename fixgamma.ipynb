{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study on Fix Gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bns=[bn for bn in list(resnet50.state_dict().keys()) if 'bn' in bn and 'weight' in bn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bns_weight=[weight for weight in bns if \"weight\" in weight]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有的bn weight取log2(abs())然后画出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.weight -10.0     1\n",
      "-3.0      4\n",
      "-2.0     50\n",
      "-1.0      9\n",
      "dtype: int64\n",
      "layer1.0.bn1.weight -10.0     5\n",
      "-3.0     27\n",
      "-2.0     31\n",
      "-1.0      1\n",
      "dtype: int64\n",
      "layer1.0.bn2.weight -10.0     3\n",
      "-9.0      1\n",
      "-3.0     37\n",
      "-2.0     23\n",
      "dtype: int64\n",
      "layer1.0.bn3.weight -10.0    32\n",
      "-9.0      2\n",
      "-8.0      8\n",
      "-7.0      5\n",
      "-6.0      9\n",
      "-5.0      8\n",
      "-4.0     34\n",
      "-3.0     69\n",
      "-2.0     88\n",
      "-1.0      1\n",
      "dtype: int64\n",
      "layer1.1.bn1.weight -10.0     4\n",
      "-3.0     28\n",
      "-2.0     32\n",
      "dtype: int64\n",
      "layer1.1.bn2.weight -3.0    29\n",
      "-2.0    35\n",
      "dtype: int64\n",
      "layer1.1.bn3.weight -10.0    21\n",
      "-9.0     20\n",
      "-8.0     17\n",
      "-7.0     11\n",
      "-6.0      9\n",
      "-5.0     13\n",
      "-4.0     53\n",
      "-3.0     90\n",
      "-2.0     22\n",
      "dtype: int64\n",
      "layer1.2.bn1.weight -3.0    26\n",
      "-2.0    38\n",
      "dtype: int64\n",
      "layer1.2.bn2.weight -3.0     4\n",
      "-2.0    60\n",
      "dtype: int64\n",
      "layer1.2.bn3.weight -10.0    26\n",
      "-9.0     22\n",
      "-8.0     30\n",
      "-7.0     23\n",
      "-6.0     13\n",
      "-5.0     11\n",
      "-4.0     35\n",
      "-3.0     54\n",
      "-2.0     41\n",
      "-1.0      1\n",
      "dtype: int64\n",
      "layer2.0.bn1.weight -3.0     25\n",
      "-2.0    103\n",
      "dtype: int64\n",
      "layer2.0.bn2.weight -3.0    29\n",
      "-2.0    99\n",
      "dtype: int64\n",
      "layer2.0.bn3.weight -10.0     79\n",
      "-9.0      18\n",
      "-8.0      23\n",
      "-7.0      26\n",
      "-6.0      16\n",
      "-5.0      17\n",
      "-4.0      39\n",
      "-3.0     158\n",
      "-2.0     136\n",
      "dtype: int64\n",
      "layer2.1.bn1.weight -4.0     18\n",
      "-3.0    104\n",
      "-2.0      6\n",
      "dtype: int64\n",
      "layer2.1.bn2.weight -4.0     3\n",
      "-3.0    85\n",
      "-2.0    40\n",
      "dtype: int64\n",
      "layer2.1.bn3.weight -10.0    38\n",
      "-9.0     26\n",
      "-8.0     48\n",
      "-7.0     64\n",
      "-6.0     55\n",
      "-5.0     62\n",
      "-4.0     41\n",
      "-3.0     81\n",
      "-2.0     96\n",
      "-1.0      1\n",
      "dtype: int64\n",
      "layer2.2.bn1.weight -3.0    72\n",
      "-2.0    56\n",
      "dtype: int64\n",
      "layer2.2.bn2.weight -3.0    55\n",
      "-2.0    73\n",
      "dtype: int64\n",
      "layer2.2.bn3.weight -10.0      1\n",
      "-9.0       2\n",
      "-8.0       7\n",
      "-7.0       9\n",
      "-6.0      21\n",
      "-5.0      39\n",
      "-4.0     157\n",
      "-3.0     219\n",
      "-2.0      57\n",
      "dtype: int64\n",
      "layer2.3.bn1.weight -3.0    84\n",
      "-2.0    44\n",
      "dtype: int64\n",
      "layer2.3.bn2.weight -3.0     23\n",
      "-2.0    105\n",
      "dtype: int64\n",
      "layer2.3.bn3.weight -10.0      8\n",
      "-9.0      10\n",
      "-8.0      20\n",
      "-7.0      24\n",
      "-6.0      37\n",
      "-5.0      66\n",
      "-4.0     120\n",
      "-3.0     166\n",
      "-2.0      61\n",
      "dtype: int64\n",
      "layer3.0.bn1.weight -3.0     13\n",
      "-2.0    243\n",
      "dtype: int64\n",
      "layer3.0.bn2.weight -3.0    114\n",
      "-2.0    142\n",
      "dtype: int64\n",
      "layer3.0.bn3.weight -10.0     40\n",
      "-9.0       2\n",
      "-7.0       2\n",
      "-6.0       6\n",
      "-5.0      34\n",
      "-4.0     133\n",
      "-3.0     523\n",
      "-2.0     284\n",
      "dtype: int64\n",
      "layer3.1.bn1.weight -3.0    201\n",
      "-2.0     55\n",
      "dtype: int64\n",
      "layer3.1.bn2.weight -3.0    101\n",
      "-2.0    152\n",
      "-1.0      3\n",
      "dtype: int64\n",
      "layer3.1.bn3.weight -10.0      6\n",
      "-9.0       2\n",
      "-8.0       1\n",
      "-7.0       3\n",
      "-6.0      13\n",
      "-5.0      46\n",
      "-4.0     342\n",
      "-3.0     556\n",
      "-2.0      54\n",
      "-1.0       1\n",
      "dtype: int64\n",
      "layer3.2.bn1.weight -3.0    207\n",
      "-2.0     49\n",
      "dtype: int64\n",
      "layer3.2.bn2.weight -3.0     91\n",
      "-2.0    165\n",
      "dtype: int64\n",
      "layer3.2.bn3.weight -10.0      2\n",
      "-8.0       1\n",
      "-7.0       3\n",
      "-6.0      11\n",
      "-5.0     119\n",
      "-4.0     407\n",
      "-3.0     446\n",
      "-2.0      35\n",
      "dtype: int64\n",
      "layer3.3.bn1.weight -3.0    173\n",
      "-2.0     83\n",
      "dtype: int64\n",
      "layer3.3.bn2.weight -3.0    136\n",
      "-2.0    120\n",
      "dtype: int64\n",
      "layer3.3.bn3.weight -10.0      5\n",
      "-9.0       3\n",
      "-8.0       4\n",
      "-7.0       9\n",
      "-6.0      41\n",
      "-5.0     136\n",
      "-4.0     319\n",
      "-3.0     480\n",
      "-2.0      27\n",
      "dtype: int64\n",
      "layer3.4.bn1.weight -3.0    170\n",
      "-2.0     86\n",
      "dtype: int64\n",
      "layer3.4.bn2.weight -3.0    114\n",
      "-2.0    142\n",
      "dtype: int64\n",
      "layer3.4.bn3.weight -10.0      2\n",
      "-9.0       5\n",
      "-8.0       6\n",
      "-7.0      13\n",
      "-6.0      25\n",
      "-5.0     154\n",
      "-4.0     318\n",
      "-3.0     458\n",
      "-2.0      43\n",
      "dtype: int64\n",
      "layer3.5.bn1.weight -3.0    103\n",
      "-2.0    153\n",
      "dtype: int64\n",
      "layer3.5.bn2.weight -3.0     70\n",
      "-2.0    184\n",
      "-1.0      2\n",
      "dtype: int64\n",
      "layer3.5.bn3.weight -10.0      1\n",
      "-9.0       1\n",
      "-8.0       2\n",
      "-7.0       7\n",
      "-6.0      10\n",
      "-5.0      27\n",
      "-4.0     355\n",
      "-3.0     536\n",
      "-2.0      85\n",
      "dtype: int64\n",
      "layer4.0.bn1.weight -3.0     14\n",
      "-2.0    498\n",
      "dtype: int64\n",
      "layer4.0.bn2.weight -3.0     98\n",
      "-2.0    414\n",
      "dtype: int64\n",
      "layer4.0.bn3.weight -5.0       3\n",
      "-4.0       4\n",
      "-3.0      12\n",
      "-2.0     901\n",
      "-1.0    1128\n",
      "dtype: int64\n",
      "layer4.1.bn1.weight -3.0    109\n",
      "-2.0    403\n",
      "dtype: int64\n",
      "layer4.1.bn2.weight -3.0     20\n",
      "-2.0    492\n",
      "dtype: int64\n",
      "layer4.1.bn3.weight -3.0       6\n",
      "-2.0    1064\n",
      "-1.0     975\n",
      "-0.0       3\n",
      "dtype: int64\n",
      "layer4.2.bn1.weight -3.0     41\n",
      "-2.0    470\n",
      "-1.0      1\n",
      "dtype: int64\n",
      "layer4.2.bn2.weight -3.0     29\n",
      "-2.0    483\n",
      "dtype: int64\n",
      "layer4.2.bn3.weight -3.0       4\n",
      "-2.0      32\n",
      "-1.0     942\n",
      "-0.0    1070\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in bns_weight:\n",
    "    #plt.figure()\n",
    "    a = np.clip(np.round(np.log2(np.abs(resnet50.state_dict()[i]))),-10,0)\n",
    "    print(i,pd.Series(a).value_counts().sort_index())\n",
    "    #sns.distplot(np.round(np.log2(np.abs(resnet50.state_dict()[i]))),kde=False)\n",
    "    #plt.title(i)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixGamma(nn.Module):\n",
    "    def __init__(self, bntype):\n",
    "        super(FixGamma, self).__init__()\n",
    "        self.bntype = bntype\n",
    "\n",
    "    def forward(self, input):\n",
    "        data=input.data\n",
    "        if self.bntype:\n",
    "            input.data[:int(len(data)/2)]=data[:int(len(data)/2)]*2**-2\n",
    "            input.data[int(len(data)/2):]=data[:int(len(data)/2)]*2**-3\n",
    "        else:\n",
    "            input.data[:int(len(data)/8)]=input.data[:int(len(data)/8)]*2**-2\n",
    "            input.data[int(len(data)/8):3*int(len(data)/8)]=input.data[int(len(data)/8):3*int(len(data)/8)]*2**-3\n",
    "            input.data[3*int(len(data)/8):6*int(len(data)/8)]=input.data[3*int(len(data)/8):6*int(len(data)/8)]*2**-4\n",
    "            input.data[6*int(len(data)/8):]=input.data[6*int(len(data)/8):]*2**-5\n",
    "        idx = torch.randperm(input.nelement())\n",
    "        output = input.view(-1)[idx].view(input.size())\n",
    "        return output\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,num):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.num=num\n",
    "        self.alldata=torch.randn(num,3,255,255)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        temp=self.alldata[idx]\n",
    "        return temp\n",
    "\n",
    "class testbn(nn.Module):\n",
    "    def __init__(self,bntype):\n",
    "        super(testbn, self).__init__()\n",
    "        self.bntype = bntype\n",
    "        self.bn1=nn.BatchNorm2d(3)\n",
    "        self.fix=FixGamma(self.bntype)\n",
    "    def forward(self,input):\n",
    "        out=self.bn1(input)\n",
    "        out=self.fix(out)\n",
    "        return out\n",
    "\n",
    "td=testDataset(100)\n",
    "dataloader = DataLoader(td, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "testmodel=testbn(False)\n",
    "\n",
    "for data in dataloader:\n",
    "    testmodel(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
